{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbed33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb0c111",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance = pd.read_csv('Insurance_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4998035",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "insurance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0a9171",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f906e048",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75766e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.shape ### no duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8889d9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d1aa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a9130c",
   "metadata": {},
   "source": [
    "#### No null values, hurray!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2689eac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d46495f",
   "metadata": {},
   "source": [
    "#### Policy tenure, age of car, and age of policy holder are normalized values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e59677",
   "metadata": {},
   "source": [
    "#### We will seperate max_torque into torque values and max_power into power:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee59d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "torque=[]\n",
    "for i in insurance['max_torque']:\n",
    "    spl_t=i.split(\"Nm\")\n",
    "    torque.append(spl_t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd00570",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.insert(loc=11, column='torque', value=torque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cccdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "power=[]\n",
    "for i in insurance['max_power']:\n",
    "    spl_p=i.split(\"bhp\")\n",
    "    power.append(spl_p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51de7c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.insert(loc=12, column='power', value=power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f95190",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.insert(loc=15, column='volume', value=round((insurance['length']*insurance['width']* insurance['height']),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7d03ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.drop(['max_power', 'max_torque', 'policy_id', 'length', 'width', 'height'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f04d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2080bba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_list=[]\n",
    "num_list=[]\n",
    "\n",
    "for i in insurance.columns:\n",
    "    unique_val=len(insurance[i].unique())\n",
    "    if i==\"area_cluster\":\n",
    "        cat_list.append(i)\n",
    "    else:\n",
    "        if unique_val<15:\n",
    "            cat_list.append(i)\n",
    "        else:\n",
    "            num_list.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee91f6f8",
   "metadata": {},
   "source": [
    "### Let's start with the Exploratory Data Analysis  ðŸ˜Ž "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbd30d3",
   "metadata": {},
   "source": [
    "#### 1. Univariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f21e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['0', '1']\n",
    "size = insurance['is_claim'].value_counts()\n",
    "colors = ['blue', 'red']\n",
    "\n",
    "plt.style.use('seaborn-deep')\n",
    "plt.pie(size, labels=labels, colors = colors, autopct = \"%.2f%%\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d64cbc3",
   "metadata": {},
   "source": [
    "#### Highly imbalanced dataset, we need to do some upsampling (will be done later)  ðŸ”¨ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b34859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_box(data):\n",
    "    Name=data.name.upper()\n",
    "    fig,(ax_box,ax_dis)  =plt.subplots(2,1,gridspec_kw = {\"height_ratios\": (.25, .75)},figsize=(8, 5))\n",
    "    mean=data.mean()\n",
    "    median=data.median()\n",
    "    mode=data.mode().tolist()[0]\n",
    "    fig.suptitle(\"SPREAD OF DATA FOR \"+ Name  , fontsize=18, fontweight='bold')\n",
    "    sns.boxplot(x=data,showmeans=True, orient='h',color=\"violet\",ax=ax_box)\n",
    "    ax_box.set(xlabel='')\n",
    "    sns.distplot(data,kde=False,color='blue',ax=ax_dis)\n",
    "    ax_dis.axvline(mean, color='r', linestyle='--',linewidth=2)\n",
    "    ax_dis.axvline(median, color='g', linestyle='-',linewidth=2)\n",
    "    ax_dis.axvline(mode, color='y', linestyle='-',linewidth=2)\n",
    "    plt.legend({'Mean':mean,'Median':median,'Mode':mode})\n",
    "\n",
    "for i in range(len(num_list)):\n",
    "    dist_box(insurance[num_list[i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f244a27",
   "metadata": {},
   "source": [
    "#### Observations  ðŸ§ \n",
    "    ####1. Max are new policies\n",
    "    ####2. People tend to buy policies for their new cars, mostly\n",
    "    ####3. After 0.5 of age, less people tend to buy policies.\n",
    "    ####4. Population_density, although seem to be numerical, is actually categorial!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06466f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_list:\n",
    "    plt.figure(figsize=(18,15))\n",
    "    sns.countplot(x=col, data=insurance, palette='Set2')\n",
    "    plt.show()\n",
    "    print(\"no. of unique values of\", col, \"is: \", insurance[col].nunique())\n",
    "    print(\"**************************************************************\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4603eb36",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "    #### 1. High number of categories>10 exist in area_cluster, model, engine_type, height\n",
    "    #### 2. C8>C2>C5 clusters\n",
    "    #### 3. Make 1 dominates the market\n",
    "    #### 4. B2 and A segments are the highest, utility is significantly low\n",
    "    #### 5. Models M1, M4 and M6 constitute a significant portion of models in market.\n",
    "    #### 6. Petrol and CNG fuel types the most common.\n",
    "    #### 7. F&D Petrol, 1.5 L U2 CRD, and K series Dual jet engines are high\n",
    "    #### 8. Cars with 2 airbags are most common.\n",
    "    #### 9. Majority cars have no TPMS, no electronic stability control (ESC) system, no parking camers, no rear window wiper, drum rear brakes, manual transmission, 5 gear boxes, power steering, front fog lights, power door locks, central locking sytem, speed alert\n",
    "    #### 10. NCAP rating of 2 is the most common, while NCAP rating of 0 is also quite high. Why??? â˜¹ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1dfe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.groupby(['fuel_type'])['fuel_type'].count().plot.pie(figsize=(7,7))\n",
    "plt.title(\"Proportion of fuel types\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e6c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.groupby(['airbags'])['airbags'].count().plot.pie(figsize=(7,7))\n",
    "plt.title(\"Proportion of airbags\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c93b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.groupby(['rear_brakes_type'])['rear_brakes_type'].count().plot.pie(figsize=(7,7))\n",
    "plt.title(\"Proportion of rear brake types\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2036927",
   "metadata": {},
   "source": [
    "#### 2. Bivariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637ee843",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "sns.histplot(\n",
    "    insurance, x=\"age_of_car\",  hue=\"is_claim\", palette=\"Set1\" , bins=25, element=\"step\",  common_norm=False,\n",
    "    stat=\"probability\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49e622e",
   "metadata": {},
   "source": [
    "#### Almost same distribution of car age with the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d69094",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "sns.histplot(\n",
    "    insurance, x=\"policy_tenure\",  hue=\"is_claim\", palette=\"Set2\" , bins=50, element=\"step\",  common_norm=False,\n",
    "    stat=\"probability\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f4b7f6",
   "metadata": {},
   "source": [
    "#### Higher policy tenure leads to higher probability of claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad67c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "sns.histplot(\n",
    "    insurance, x=\"age_of_policyholder\",  hue=\"is_claim\", palette=\"Set2\" , bins=50, element=\"step\",  common_norm=False,\n",
    "    stat=\"probability\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585625d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "sns.countplot(x='make', hue ='is_claim', data=insurance, palette='Set2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be8fd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "sns.countplot(x='ncap_rating', hue ='is_claim', data=insurance, palette='Set1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dcedc8",
   "metadata": {},
   "source": [
    "#### No claims passed for the safest cars!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a1e6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "sns.countplot(x='is_ecw', hue ='is_claim', data=insurance, palette='Set2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e43be1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "sns.countplot(x='is_parking_sensors', hue ='is_claim', data=insurance, palette='Set2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c3d197",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "sns.countplot(x='is_central_locking', hue ='is_claim', data=insurance, palette='Set2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549c537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "sns.countplot(x='is_power_door_locks', hue ='is_claim', data=insurance, palette='Set2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714bbdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "sns.countplot(x='steering_type', hue ='is_claim', data=insurance, palette='Set2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51b8a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "sns.countplot(x='ncap_rating', hue ='transmission_type', data=insurance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74f2b9d",
   "metadata": {},
   "source": [
    "#### â­â­â­ rating cars are fully automatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c398f33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x ='age_of_car',y ='age_of_policyholder', hue=\"fuel_type\", data = insurance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c40756",
   "metadata": {},
   "source": [
    "#### Outlier treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18851d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['policy_tenure', 'age_of_car', 'age_of_policyholder']:\n",
    "    percentile25 = insurance[i].quantile(0.25)\n",
    "    percentile75 = insurance[i].quantile(0.75)\n",
    "\n",
    "    iqr = percentile75 - percentile25\n",
    "    \n",
    "    upper_limit = percentile75 + 1.5 * iqr\n",
    "    lower_limit = percentile25 - 1.5 * iqr\n",
    "    oulier_count=len(insurance[insurance[i]>upper_limit])+len(insurance[insurance[i]<lower_limit])\n",
    "    print(\"The no. of outliers in\", i, 'is', oulier_count)\n",
    "    upper_array = np.where(insurance[i]>=upper_limit)[0]\n",
    "    lower_array = np.where(insurance[i]<=lower_limit)[0]\n",
    " \n",
    "    # Removing the outliers\n",
    "    insurance.drop(index=upper_array, inplace=True)\n",
    "    insurance.drop(index=lower_array, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899fdbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cdb639",
   "metadata": {},
   "source": [
    "#### Determining numerical, ordinal, and nominal cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55eea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols=['policy_tenure', 'age_of_car', 'age_of_policyholder']\n",
    "ord_cols=['population_density', 'torque', 'power', 'airbags', 'displacement', 'cylinder', 'gear_box', 'turning_radius', \n",
    "          'volume', 'gross_weight', 'ncap_rating']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bf8396",
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_cols=[]\n",
    "for i in insurance.columns[:40]:\n",
    "    if i not in ord_cols and i not in num_cols:\n",
    "        nom_cols.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc41c130",
   "metadata": {},
   "outputs": [],
   "source": [
    "(nom_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3952a08b",
   "metadata": {},
   "source": [
    "#### Encoding both nominal and ordincal categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe2a0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = insurance.drop(['is_claim'], axis=1)\n",
    "y = insurance[\"is_claim\"]\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf6bfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "oe=OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b93395",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ord_cols:\n",
    "    x_train[col]=oe.fit_transform(x_train[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02994f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_enc = pd.get_dummies(x_train, columns = nom_cols, drop_first= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6dbc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_enc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a9749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ord_cols:\n",
    "    x_test[col]=oe.fit_transform(x_test[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0362df",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_enc = pd.get_dummies(x_test, columns = nom_cols, drop_first= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0d42f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_enc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3891b4f5",
   "metadata": {},
   "source": [
    "### Feature selection\n",
    "#### 1. Correlation with target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305f4151",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all=pd.concat([x_train_enc, y_train], axis=1) ### Checking for low correlation with target!!\n",
    "cor=x_all.corr()[\"is_claim\"].sort_values(ascending=False)\n",
    "correlate=pd.DataFrame({\"Column\":cor.index,\"Correlation with target\":cor.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9546d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlate.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097b6270",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_corr=correlate.loc[abs(correlate['Correlation with target']) <= 0.005, 'Column'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc67a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(low_corr) ## Found 38 low-correlation columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffaa41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all_1=x_all.drop(columns=low_corr)\n",
    "corr= x_all_1.corr()\n",
    "# Getting the Upper Triangle of the co-relation matrix\n",
    "matrix = np.triu(corr)\n",
    "\n",
    "# using the upper triangle matrix as mask \n",
    "plt.figure(figsize=(40,40))\n",
    "plt.title(\"Heatmap excluding the low-correlation columns\", fontsize=20)\n",
    "sns.heatmap(corr, annot=True, mask=matrix, cmap=\"coolwarm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8868eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some more columns need to be removed!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dab81eb",
   "metadata": {},
   "source": [
    "#### 2. Multicollinearity of independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9afb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = x_all_1.corr().columns\n",
    "\n",
    "# Create an empty list to keep track of columns to drop\n",
    "columns_to_drop = []\n",
    "\n",
    "# Loop over the columns\n",
    "for i in range(len(columns)):\n",
    "    for j in range(i + 1, len(columns)):\n",
    "        # Access the cell of the DataFrame\n",
    "        if (x_all_1.corr().loc[columns[i], columns[j]]) > 0.8 or (x_all_1.corr().loc[columns[i], columns[j]]) <-0.8:\n",
    "            columns_to_drop.append(columns[j])\n",
    "\n",
    "print(len(columns_to_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b9c4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = set(columns_to_drop) ## using set as there are duplicate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727b1e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecea1051",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all_2=x_all_1.drop(columns=columns_to_drop)\n",
    "corr=x_all_2.corr()\n",
    "# Getting the Upper Triangle of the co-relation matrix\n",
    "matrix = np.triu(corr)\n",
    "\n",
    "# using the upper triangle matrix as mask \n",
    "plt.figure(figsize=(28,28))\n",
    "plt.title(\"Heatmap excluding the low-correlation and multicollinearity\", fontsize=20)\n",
    "sns.heatmap(corr, annot=True, mask=matrix, cmap=\"coolwarm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a024e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_all_2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bae270",
   "metadata": {},
   "source": [
    "#### Modelling starts!! We will be using different cases, shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97f6459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00485fd7",
   "metadata": {},
   "source": [
    "#### Case 1: Using dataset without samling or FS (feature selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8806fc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression(random_state=42)\n",
    "dtc=DecisionTreeClassifier(random_state=42)\n",
    "rfc=RandomForestClassifier(random_state=42)\n",
    "gbc=GradientBoostingClassifier(random_state=42)\n",
    "xgb=XGBClassifier(random_state=42)\n",
    "ada = AdaBoostClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35561640",
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[lr,dtc,rfc,gbc, xgb, ada]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7b4a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.model_selection import RepeatedStratifiedKFold ## better for dealing with imbalanced datasets\n",
    "for model in models:\n",
    "    print(\"Model: \", model)\n",
    "    for scoring in[\"balanced_accuracy\", \"f1\"]:\n",
    "        cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "        scores = cross_val_score(model, x_train_enc, y_train, scoring=scoring, cv=cv, n_jobs=-1)\n",
    "        \n",
    "        print(scoring, \" mean=\", scores.mean(), \" SD= \", scores.std())\n",
    "        \n",
    "    print(\"*********************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335b96d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(models, x_train, y_train, x_test):\n",
    "    for model in models:\n",
    "    \n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "        accuracy = round(balanced_accuracy_score(y_test, y_pred),3)\n",
    "        precision = round(precision_score(y_test, y_pred), 3)\n",
    "        recall = round(recall_score(y_test, y_pred), 3)\n",
    "        F1_score = round(f1_score(y_test, y_pred), 3)\n",
    "    \n",
    "        print(\"For \", model)\n",
    "        print(\"Balanced accuracy: \", accuracy, \" Precision: \", precision, \" Recall: \", recall, \" F1 score: \", F1_score)\n",
    "    \n",
    "        \n",
    "        classif_rep = classification_report(y_test, y_pred)\n",
    "        print(\"Classification Report:\\n\", classif_rep)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9862dd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CASE 1: UNTREATED DATASET:      \\n\")\n",
    "model_evaluation(models, x_train_enc, y_train, x_test_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162dc982",
   "metadata": {},
   "source": [
    "#### Case 2: Using upsampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5276337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "sampler = RandomOverSampler(random_state=1)\n",
    "x_train_over, y_train_over = sampler.fit_resample(x_train_enc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83e662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before resampling: \", y_train.value_counts())\n",
    "print(\"After resampling: \", y_train_over.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c64963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CASE 2: UPSAMPLED DATASET:      \\n\")\n",
    "model_evaluation(models, x_train_over, y_train_over, x_test_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2985a7df",
   "metadata": {},
   "source": [
    "#### Case 3: Using FS (low-correlation and multicollinearity excluded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c00618",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sel=x_train_over.drop(columns=low_corr)\n",
    "x_test_sel=x_test_enc.drop(columns=low_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec656c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sel=x_train_sel.drop(columns=columns_to_drop)\n",
    "x_test_sel=x_test_sel.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ef9e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sel.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e3735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CASE 3: FEATURE SELECTION USING CORRELATION:      \\n\")\n",
    "model_evaluation(models, x_train_sel, y_train_over, x_test_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afde319",
   "metadata": {},
   "source": [
    "#### Case 4: Using FS (chi square) method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f7ee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate chi-squared stats\n",
    "chi_scores = chi2(x_train_over, y_train_over)\n",
    "\n",
    "# chi_scores[1] are the p-values of each feature.\n",
    "p_values = pd.Series(chi_scores[1], index = x_train_over.columns)\n",
    "p_values.sort_values(inplace = True)\n",
    "\n",
    "# Plotting the p-values\n",
    "plt.figure(dpi=100, figsize=(20, 20))\n",
    "p_values.plot.bar()\n",
    "\n",
    "plt.title('Chi-square test - P-values', fontsize=18)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('P-value')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf3fe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "sel_30_cols = SelectKBest(score_func=chi2, k=30) ## selecting 30 best columns\n",
    "sel_30_cols.fit(x_train_over, y_train_over)\n",
    "sel_cols=x_train_over.columns[sel_30_cols.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d3f6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_chisquare = x_train_over.loc[:,x_train_over.columns.isin(sel_cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56715745",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_chisquare = x_test_enc.loc[:,x_test_enc.columns.isin(sel_cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6716bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CASE 4: FEATURE SELECTION USING CHI SQUARE TEST      \\n\")\n",
    "model_evaluation(models, x_train_chisquare, y_train_over, x_test_chisquare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cd54a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "sampler_under = RandomUnderSampler(random_state=1)\n",
    "x_train_under, y_train_under = sampler_under.fit_resample(x_train_enc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fc986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CASE 5: DOWNSAMPLED DATASET      \\n\")\n",
    "model_evaluation(models, x_train_under, y_train_under, x_test_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12aaf0c",
   "metadata": {},
   "source": [
    "#### Comparing all the cases, we see that GradBoost Classifier results in the highest accuracy and F1 score, when trained on the upsampled data with feature selection (case 3). \n",
    "\n",
    "#### So now, I will perform a hyperparameter tuning!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd07c2a",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning (Warning: Very computationally expensive!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff99f60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "p_test1 = {'learning_rate':[0.01,0.05,0.1,0.15,0.2], 'n_estimators':[100,250,500,750,1000,1250,1500]}\n",
    "\n",
    "tuning = GridSearchCV(estimator =GradientBoostingClassifier(max_depth=6, min_samples_split=200, min_samples_leaf=40, subsample=1,max_features='sqrt', random_state=10), param_grid = p_test1, scoring='f1',n_jobs=4, cv=5)\n",
    "tuning.fit(x_train_sel, y_train_over)\n",
    "\n",
    "tuning.best_params_, tuning.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4d0a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21b3b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test2 = {'max_depth':[3,4,5,6,7,8] }\n",
    "\n",
    "tuning = GridSearchCV(estimator =GradientBoostingClassifier(learning_rate=0.2,n_estimators=1500,min_samples_split=200, min_samples_leaf=40, subsample=1,max_features='sqrt', random_state=10), \n",
    "            param_grid = p_test2, scoring='f1',n_jobs=4, cv=5)\n",
    "tuning.fit(x_train_sel, y_train_over)\n",
    "\n",
    "tuning.best_params_, tuning.best_score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfdfb73",
   "metadata": {},
   "source": [
    "##### Below, I have manually tuned the hyperparameters again to find the optimum values\n",
    "##### learning_rate=0.02, n_estimators=300,max_depth=4, min_samples_split=700, min_samples_leaf=30,max_features=5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583a8875",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model=GradientBoostingClassifier(learning_rate=0.02, n_estimators=300,max_depth=4, min_samples_split=700, min_samples_leaf=30,max_features=5, subsample=1, random_state=10)\n",
    "new_model.fit(x_train_sel, y_train_over)\n",
    "y_pred=new_model.predict(x_test_sel)\n",
    "print(\"Final balanced accuracy\", round(balanced_accuracy_score(y_test, y_pred),3))\n",
    "print(\"Final F1 score\", round(f1_nscore(y_test, y_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76799fe0",
   "metadata": {},
   "source": [
    "#### Not any improvement seen !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3668013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48afeaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_roc_auc = roc_auc_score(y_test, y_pred)\n",
    "fpr1, tpr1, thresholds1 = roc_curve(y_test, new_model.predict_proba(x_test_sel)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bed910",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr1, tpr1, label='XBG Model (area = %0.2f)' % model_roc_auc)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
